# Signify

Signify is *Alexa for the deaf*. 

It is a machine learning app designed to offer AI assistance to individuals who use American Sign Language (ASL) for communication. It aims to enable seamless interactions with AI assistants through ASL, enhancing accessibility for the deaf community.

<div align="center">
    <img src="./assets/logo.jpg" alt="Signify Logo" width="400">
</div>

## Tools used

- [Python](https://docs.python.org/3/)
- [MediaPipe](https://google.github.io/mediapipe/)
- [TensorFlow](https://www.tensorflow.org/overview)
- [Anaconda](https://docs.anaconda.com/)
- [Flask](https://flask.palletsprojects.com/)
- [Jupyter Notebook](https://jupyter-notebook.readthedocs.io/en/stable/)
- [OpenCV](https://docs.opencv.org/master/)


## Resources

- [Gesture recognition guide for Python](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/python)
- [Hand gesture recognition model customization guide](https://developers.google.com/mediapipe/solutions/customization/gesture_recognizer)
- [Udemy complete AI and ML Bootcamp by ZTM](https://www.udemy.com/share/102vAM3@uzvhf-FWASuZvecZ9RCJyF9n25CqgKAtCSlxnOch3PB_A_F7ZEdAXJ9b6V1QUXEo/)